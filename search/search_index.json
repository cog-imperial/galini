{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"GALINI Getting Started Installation GALINI has not been released to Pypi yet. You will need to install it manually. The first step is to download GALINI source: git clone https://github.com/fracek/galini.git GALINI requires a working installation of Ipopt to work. Refer to Ipopt documentation , set the IPOPT_INCLUDE_DIR and IPOPT_LIBRARY_DIR environment variables to Ipopt include and library directories respectively. You also need to update the LD_LIBRARY_PATH environment variable to include Ipopt library directory. After that, you should be able to install it with: python setup.py install And test everything is installed correctly with: python setup.py test Running To see the list of available commands run the galini command: $ galini usage: galini [-h] {dot,solve} ... positional arguments: {dot,solve} dot Save GALINI DAG of the problem as Graphviz Dot file solve Solve a MINLP optional arguments: -h, --help show this help message and exit Troubleshooting Ipopt related errors Please check out Pypopt README .","title":"Home"},{"location":"#galini","text":"","title":"GALINI"},{"location":"#getting-started","text":"","title":"Getting Started"},{"location":"#installation","text":"GALINI has not been released to Pypi yet. You will need to install it manually. The first step is to download GALINI source: git clone https://github.com/fracek/galini.git GALINI requires a working installation of Ipopt to work. Refer to Ipopt documentation , set the IPOPT_INCLUDE_DIR and IPOPT_LIBRARY_DIR environment variables to Ipopt include and library directories respectively. You also need to update the LD_LIBRARY_PATH environment variable to include Ipopt library directory. After that, you should be able to install it with: python setup.py install And test everything is installed correctly with: python setup.py test","title":"Installation"},{"location":"#running","text":"To see the list of available commands run the galini command: $ galini usage: galini [-h] {dot,solve} ... positional arguments: {dot,solve} dot Save GALINI DAG of the problem as Graphviz Dot file solve Solve a MINLP optional arguments: -h, --help show this help message and exit","title":"Running"},{"location":"#troubleshooting","text":"","title":"Troubleshooting"},{"location":"#ipopt-related-errors","text":"Please check out Pypopt README .","title":"Ipopt related errors"},{"location":"configuration/","text":"Configuration","title":"Configuration"},{"location":"configuration/#configuration","text":"","title":"Configuration"},{"location":"logging/","text":"","title":"Logging"},{"location":"relaxations/","text":"Developing Relaxations GALINI provides an intuitive interface to develop relaxations. All you have to do is implement the Relaxation interface from galini.relaxations . This interface requires you to implement two methods: can_relax and relax . The first method takes a problem, expression and context in input and returns a boolean value to indicate whether the current relaxation can relax the given expression. The second method takes the same problem, expression and context as the previous one and returns a RelaxationResult . A RelaxationResult is an object that contains a new expression and constraints. The old expression will be replaced by the new expression, and the constraints will be added to the problem.","title":"Relaxations"},{"location":"relaxations/#developing-relaxations","text":"GALINI provides an intuitive interface to develop relaxations. All you have to do is implement the Relaxation interface from galini.relaxations . This interface requires you to implement two methods: can_relax and relax . The first method takes a problem, expression and context in input and returns a boolean value to indicate whether the current relaxation can relax the given expression. The second method takes the same problem, expression and context as the previous one and returns a RelaxationResult . A RelaxationResult is an object that contains a new expression and constraints. The old expression will be replaced by the new expression, and the constraints will be added to the problem.","title":"Developing Relaxations"},{"location":"underestimators/","text":"Underestimators Bilinear Terms Given the bilinear term xy xy over the domain [x^L, x^U] \\times [y^L, y^U] [x^L, x^U] \\times [y^L, y^U] , a convex underestimator by introducing a new variable w w that satisfies the following relationship: w = \\max{\\{x^L y + y^L x - x^L y^L; x^U y + y^U x - x^U y^U\\}} w = \\max{\\{x^L y + y^L x - x^L y^L; x^U y + y^U x - x^U y^U\\}} This expression can be included in the minimization problem as [1]: \\begin{align} w \\geq & x^Ly + y^Lx -x^Ly^L \\\\ w \\geq & x^Uy + y^Ux - x^Uy^U \\\\ w \\geq & x^Uy + y^Lx - x^Uy^L \\\\ w \\geq & x^Ly + y^Ux - x^Ly^U \\end{align} \\begin{align} w \\geq & x^Ly + y^Lx -x^Ly^L \\\\ w \\geq & x^Uy + y^Ux - x^Uy^U \\\\ w \\geq & x^Uy + y^Lx - x^Uy^L \\\\ w \\geq & x^Ly + y^Ux - x^Ly^U \\end{align} aBB Underestimator Given a nonconvex expression f(x) f(x) , a convex underestimator \\ell(x) \\ell(x) can be defined as [2]: \\ell(x) = f(x) + \\sum_i \\alpha_i (x_i^L - x_i)(x_i^U - x_i) \\ell(x) = f(x) + \\sum_i \\alpha_i (x_i^L - x_i)(x_i^U - x_i) where \\alpha_i \\geq \\max{\\{0, -\\frac{1}{2} \\min_{x} \\lambda(x) \\}} \\alpha_i \\geq \\max{\\{0, -\\frac{1}{2} \\min_{x} \\lambda(x) \\}} where \\lambda(x) \\lambda(x) are the eigenvalues of the Hessian matrix of f(x) f(x) . References [1] McCormick, G. P. (1976). Computability of global solutions to factorable nonconvex programs: Part I \u2014 Convex underestimating problems. Mathematical Programming, 10(1), 147\u2013175. https://doi.org/10.1007/BF01580665 [2] Androulakis, I. P., Maranas, C. D., & Floudas, C. A. (1995). \u03b1BB: A global optimization method for general constrained nonconvex problems. Journal of Global Optimization, 7(4), 337\u2013363. https://doi.org/10.1007/BF01099647","title":"Underestimators"},{"location":"underestimators/#underestimators","text":"","title":"Underestimators"},{"location":"underestimators/#bilinear-terms","text":"Given the bilinear term xy xy over the domain [x^L, x^U] \\times [y^L, y^U] [x^L, x^U] \\times [y^L, y^U] , a convex underestimator by introducing a new variable w w that satisfies the following relationship: w = \\max{\\{x^L y + y^L x - x^L y^L; x^U y + y^U x - x^U y^U\\}} w = \\max{\\{x^L y + y^L x - x^L y^L; x^U y + y^U x - x^U y^U\\}} This expression can be included in the minimization problem as [1]: \\begin{align} w \\geq & x^Ly + y^Lx -x^Ly^L \\\\ w \\geq & x^Uy + y^Ux - x^Uy^U \\\\ w \\geq & x^Uy + y^Lx - x^Uy^L \\\\ w \\geq & x^Ly + y^Ux - x^Ly^U \\end{align} \\begin{align} w \\geq & x^Ly + y^Lx -x^Ly^L \\\\ w \\geq & x^Uy + y^Ux - x^Uy^U \\\\ w \\geq & x^Uy + y^Lx - x^Uy^L \\\\ w \\geq & x^Ly + y^Ux - x^Ly^U \\end{align}","title":"Bilinear Terms"},{"location":"underestimators/#abb-underestimator","text":"Given a nonconvex expression f(x) f(x) , a convex underestimator \\ell(x) \\ell(x) can be defined as [2]: \\ell(x) = f(x) + \\sum_i \\alpha_i (x_i^L - x_i)(x_i^U - x_i) \\ell(x) = f(x) + \\sum_i \\alpha_i (x_i^L - x_i)(x_i^U - x_i) where \\alpha_i \\geq \\max{\\{0, -\\frac{1}{2} \\min_{x} \\lambda(x) \\}} \\alpha_i \\geq \\max{\\{0, -\\frac{1}{2} \\min_{x} \\lambda(x) \\}} where \\lambda(x) \\lambda(x) are the eigenvalues of the Hessian matrix of f(x) f(x) .","title":"aBB Underestimator"},{"location":"underestimators/#references","text":"[1] McCormick, G. P. (1976). Computability of global solutions to factorable nonconvex programs: Part I \u2014 Convex underestimating problems. Mathematical Programming, 10(1), 147\u2013175. https://doi.org/10.1007/BF01580665 [2] Androulakis, I. P., Maranas, C. D., & Floudas, C. A. (1995). \u03b1BB: A global optimization method for general constrained nonconvex problems. Journal of Global Optimization, 7(4), 337\u2013363. https://doi.org/10.1007/BF01099647","title":"References"},{"location":"bab/branching/","text":"Branching Strategies You can pass a branching strategy to a B&B node to decide on which variable to branch. Four alternatives implemented [1]: K-section Maximum separation distance between underestimator and term Separation distance at optimum Influence of each variable on the quality of the lower bounding problem K-section Pick the least reduced axis , that is the axis with the largest r_i r_i defined as: r_i = \\frac{x_i^U - x_i^L}{x_{i,0}^U - x_{i,0}^L} r_i = \\frac{x_i^U - x_i^L}{x_{i,0}^U - x_{i,0}^L} where x_i^U x_i^U and x_i^L x_i^L are x_i x_i bounds at the current node, and x_{i,0}^U x_{i,0}^U and x_{i,0}^L x_{i,0}^L are the bounds at the root node. Maximum separation distance 1 We define a new measure \\mu \\mu to asses the quality of the underestimator. For a bilinear term xy xy , the maximum separation distance was derived by [2] so that \\mu_b \\mu_b is: \\mu_b = \\frac{1}{4}(x^U - x^L)(y^U - y^L) \\mu_b = \\frac{1}{4}(x^U - x^L)(y^U - y^L) The term with the worst underestimator is used as the basis for the branching variable. Out of the variables that participate in the term, the one with the least reduced axis r_i r_i is picked. Maximum separation distance 1 This strategy is a variation of the previous one. We compute the maximum separation distance at the optimum. Influence of each variable on the quality of the lower bounding problem This branching strategy considers the influence of each variable on the convex problem. After the quantities \\mu \\mu have been computed for each term, a measure \\mu_v \\mu_v of each variable contribution is defined as the sum of quantities \\mu \\mu in which the variable participates. Reference [1] Adjiman, C. S., Androulakis, I. P., & Floudas, C. A. (1998). A global optimization method, \u03b1BB, for general twice-differentiable constrained NLPs\u2014II. Implementation and computational results. Computers & Chemical Engineering, 22(9), 1159\u20131179. https://doi.org/10.1016/S0098-1354(98)00218-Xs [2] Androulakis, I. P., Maranas, C. D., & Floudas, C. A. (1995). \u03b1BB: A global optimization method for general constrained nonconvex problems. Journal of Global Optimization, 7(4), 337\u2013363. https://doi.org/10.1007/BF01099647","title":"Branching"},{"location":"bab/branching/#branching-strategies","text":"You can pass a branching strategy to a B&B node to decide on which variable to branch. Four alternatives implemented [1]: K-section Maximum separation distance between underestimator and term Separation distance at optimum Influence of each variable on the quality of the lower bounding problem","title":"Branching Strategies"},{"location":"bab/branching/#k-section","text":"Pick the least reduced axis , that is the axis with the largest r_i r_i defined as: r_i = \\frac{x_i^U - x_i^L}{x_{i,0}^U - x_{i,0}^L} r_i = \\frac{x_i^U - x_i^L}{x_{i,0}^U - x_{i,0}^L} where x_i^U x_i^U and x_i^L x_i^L are x_i x_i bounds at the current node, and x_{i,0}^U x_{i,0}^U and x_{i,0}^L x_{i,0}^L are the bounds at the root node.","title":"K-section"},{"location":"bab/branching/#maximum-separation-distance-1","text":"We define a new measure \\mu \\mu to asses the quality of the underestimator. For a bilinear term xy xy , the maximum separation distance was derived by [2] so that \\mu_b \\mu_b is: \\mu_b = \\frac{1}{4}(x^U - x^L)(y^U - y^L) \\mu_b = \\frac{1}{4}(x^U - x^L)(y^U - y^L) The term with the worst underestimator is used as the basis for the branching variable. Out of the variables that participate in the term, the one with the least reduced axis r_i r_i is picked.","title":"Maximum separation distance 1"},{"location":"bab/branching/#maximum-separation-distance-1_1","text":"This strategy is a variation of the previous one. We compute the maximum separation distance at the optimum.","title":"Maximum separation distance 1"},{"location":"bab/branching/#influence-of-each-variable-on-the-quality-of-the-lower-bounding-problem","text":"This branching strategy considers the influence of each variable on the convex problem. After the quantities \\mu \\mu have been computed for each term, a measure \\mu_v \\mu_v of each variable contribution is defined as the sum of quantities \\mu \\mu in which the variable participates.","title":"Influence of each variable on the quality of the lower bounding problem"},{"location":"bab/branching/#reference","text":"[1] Adjiman, C. S., Androulakis, I. P., & Floudas, C. A. (1998). A global optimization method, \u03b1BB, for general twice-differentiable constrained NLPs\u2014II. Implementation and computational results. Computers & Chemical Engineering, 22(9), 1159\u20131179. https://doi.org/10.1016/S0098-1354(98)00218-Xs [2] Androulakis, I. P., Maranas, C. D., & Floudas, C. A. (1995). \u03b1BB: A global optimization method for general constrained nonconvex problems. Journal of Global Optimization, 7(4), 337\u2013363. https://doi.org/10.1007/BF01099647","title":"Reference"},{"location":"commands/dot/","text":"dot command GALINI provides a command to output a problem DAG to Graphviz DOT files. This is useful when debugging code that needs to traverse the DAG. Usage galini dot [-h] problem [out] Example Given the following input file problem.py import pyomo.environ as aml def get_pyomo_model(): m = aml.ConcreteModel() m.x = aml.Var(range(2), bounds=(0, 4.0)) m.y = aml.Var(range(2), bounds=(0, 1), domain=aml.Integers) m.obj = aml.Objective(expr=m.y[0] + m.y[1] + m.x[0]**2 + m.x[1]**2) m.c0 = aml.Constraint(expr=(m.x[0] - 2)**2 - m.x[1] <= 0) m.c1 = aml.Constraint(expr=m.x[0] - 2*m.y[0] >= 0) m.c2 = aml.Constraint(expr=m.x[0] - m.x[1] - 3*(1 - m.y[0]) <= 0) m.c3 = aml.Constraint(expr=m.x[0] - (1 - m.y[0]) >= 0) m.c4 = aml.Constraint(expr=m.x[1] - m.y[1] >= 0) m.c5 = aml.Constraint(expr=m.x[0] + m.x[1] >= 3*m.y[0]) m.c6 = aml.Constraint(expr=m.y[0] + m.y[1] >= 1) we run galini dot to obtain a .dot file galini dot problem.py problem.dot and we compile it to visualize the DAG dot -T png -o problem.png problem.dot","title":"dot"},{"location":"commands/dot/#dot-command","text":"GALINI provides a command to output a problem DAG to Graphviz DOT files. This is useful when debugging code that needs to traverse the DAG.","title":"dot command"},{"location":"commands/dot/#usage","text":"galini dot [-h] problem [out]","title":"Usage"},{"location":"commands/dot/#example","text":"Given the following input file problem.py import pyomo.environ as aml def get_pyomo_model(): m = aml.ConcreteModel() m.x = aml.Var(range(2), bounds=(0, 4.0)) m.y = aml.Var(range(2), bounds=(0, 1), domain=aml.Integers) m.obj = aml.Objective(expr=m.y[0] + m.y[1] + m.x[0]**2 + m.x[1]**2) m.c0 = aml.Constraint(expr=(m.x[0] - 2)**2 - m.x[1] <= 0) m.c1 = aml.Constraint(expr=m.x[0] - 2*m.y[0] >= 0) m.c2 = aml.Constraint(expr=m.x[0] - m.x[1] - 3*(1 - m.y[0]) <= 0) m.c3 = aml.Constraint(expr=m.x[0] - (1 - m.y[0]) >= 0) m.c4 = aml.Constraint(expr=m.x[1] - m.y[1] >= 0) m.c5 = aml.Constraint(expr=m.x[0] + m.x[1] >= 3*m.y[0]) m.c6 = aml.Constraint(expr=m.y[0] + m.y[1] >= 1) we run galini dot to obtain a .dot file galini dot problem.py problem.dot and we compile it to visualize the DAG dot -T png -o problem.png problem.dot","title":"Example"},{"location":"commands/special_structure/","text":"special_structure command This command can be used to run the special structure detection rules implemented by SUSPECT . Usage galini special_structure [-h] problem Example Given the following input file problem.py import pyomo.environ as aml def get_pyomo_model(): m = aml.ConcreteModel() m.x = aml.Var(range(2), bounds=(0, 4.0)) m.y = aml.Var(range(2), bounds=(0, 1), domain=aml.Integers) m.obj = aml.Objective(expr=m.y[0] + m.y[1] + m.x[0]**2 + m.x[1]**2) m.c0 = aml.Constraint(expr=(m.x[0] - 2)**2 - m.x[1] <= 0) m.c1 = aml.Constraint(expr=m.x[0] - 2*m.y[0] >= 0) m.c2 = aml.Constraint(expr=m.x[0] - m.x[1] - 3*(1 - m.y[0]) <= 0) m.c3 = aml.Constraint(expr=m.x[0] - (1 - m.y[0]) >= 0) m.c4 = aml.Constraint(expr=m.x[1] - m.y[1] >= 0) m.c5 = aml.Constraint(expr=m.x[0] + m.x[1] >= 3*m.y[0]) m.c6 = aml.Constraint(expr=m.y[0] + m.y[1] >= 1) we run galini special_structure and obtain the following output: Var. Dom. LB UB =========================== x[0] R 0.000 4.000 x[1] R 0.000 4.000 y[0] I 0.000 1.000 y[1] I 0.000 1.000 Obj. LB UB Cvx Mono ====================================== obj 0.000 inf Convex Nondecr. Cons. LB UB Cvx Mono ========================================== c0 -4.000 inf Convex c1 -2.000 4.000 Linear c2 -7.000 4.000 Linear c3 -1.000 4.000 Linear Nondecr. c4 -1.000 4.000 Linear c5 -8.000 3.000 Linear c6 0.000 2.000 Linear Nondecr.","title":"special_structure"},{"location":"commands/special_structure/#special_structure-command","text":"This command can be used to run the special structure detection rules implemented by SUSPECT .","title":"special_structure command"},{"location":"commands/special_structure/#usage","text":"galini special_structure [-h] problem","title":"Usage"},{"location":"commands/special_structure/#example","text":"Given the following input file problem.py import pyomo.environ as aml def get_pyomo_model(): m = aml.ConcreteModel() m.x = aml.Var(range(2), bounds=(0, 4.0)) m.y = aml.Var(range(2), bounds=(0, 1), domain=aml.Integers) m.obj = aml.Objective(expr=m.y[0] + m.y[1] + m.x[0]**2 + m.x[1]**2) m.c0 = aml.Constraint(expr=(m.x[0] - 2)**2 - m.x[1] <= 0) m.c1 = aml.Constraint(expr=m.x[0] - 2*m.y[0] >= 0) m.c2 = aml.Constraint(expr=m.x[0] - m.x[1] - 3*(1 - m.y[0]) <= 0) m.c3 = aml.Constraint(expr=m.x[0] - (1 - m.y[0]) >= 0) m.c4 = aml.Constraint(expr=m.x[1] - m.y[1] >= 0) m.c5 = aml.Constraint(expr=m.x[0] + m.x[1] >= 3*m.y[0]) m.c6 = aml.Constraint(expr=m.y[0] + m.y[1] >= 1) we run galini special_structure and obtain the following output: Var. Dom. LB UB =========================== x[0] R 0.000 4.000 x[1] R 0.000 4.000 y[0] I 0.000 1.000 y[1] I 0.000 1.000 Obj. LB UB Cvx Mono ====================================== obj 0.000 inf Convex Nondecr. Cons. LB UB Cvx Mono ========================================== c0 -4.000 inf Convex c1 -2.000 4.000 Linear c2 -7.000 4.000 Linear c3 -1.000 4.000 Linear Nondecr. c4 -1.000 4.000 Linear c5 -8.000 3.000 Linear c6 0.000 2.000 Linear Nondecr.","title":"Example"}]}